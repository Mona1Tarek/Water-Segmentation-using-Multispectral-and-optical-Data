{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hzPN24H_PS02"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate, Conv2DTranspose, Cropping2D, ZeroPadding2D\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import os\n",
        "import tifffile\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models.segmentation as models\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#The dataset\n"
      ],
      "metadata": {
        "id": "zklOjgMkS6EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjZMppP9THFJ",
        "outputId": "8184e5f8-72a7-4bb8-c6b6-b50bc835177f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Image Preprocessing"
      ],
      "metadata": {
        "id": "yfox_NRrlxGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import transforms\n",
        "import torch\n",
        "\n",
        "def preprocess_image(image, label):\n",
        "    # Normalize image by converting it to the range [0, 1]\n",
        "    image = image / 255.0  # the images are 12-channel, so keep all channels\n",
        "\n",
        "    # Resize the image and label\n",
        "    transform_image = transforms.Compose([\n",
        "        transforms.ToTensor(),  # Convert to Tensor\n",
        "        transforms.Resize((128, 128))  # Resize to 128x128 if needed\n",
        "    ])\n",
        "\n",
        "    transform_label = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Resize((128, 128))  # Resize to 128x128 if needed\n",
        "    ])\n",
        "\n",
        "    # Apply transformations\n",
        "    image = transform_image(image).float()\n",
        "    label = transform_label(label).long().squeeze(0)  # Convert label to long tensor\n",
        "\n",
        "    return image, label\n",
        "\n"
      ],
      "metadata": {
        "id": "yhmLqSBflwb-"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_files, label_files, transform=None):\n",
        "        self.image_files = image_files\n",
        "        self.label_files = label_files\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Load the image and label\n",
        "        image = tifffile.imread(self.image_files[idx])  # Load 12-channel image\n",
        "        label = Image.open(self.label_files[idx])  # Load label as grayscale\n",
        "        label = np.array(label)  # Convert label to numpy array\n",
        "\n",
        "        if self.transform:\n",
        "            image, label = self.transform(image, label)\n",
        "\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "0Dp6WbhLqVFu"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading the data and creating dataLoader"
      ],
      "metadata": {
        "id": "b3K2PpyRl7yh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths\n",
        "images_path = '/content/drive/MyDrive/data/images'\n",
        "labels_path = '/content/drive/MyDrive/data/labels'\n",
        "\n",
        "# Load all image and label files\n",
        "image_files = [os.path.join(images_path, f) for f in os.listdir(images_path) if f.endswith('.tif')]\n",
        "label_files = [os.path.join(labels_path, f) for f in os.listdir(labels_path) if f.endswith('.png')]\n",
        "\n",
        "# Sort files to ensure they match\n",
        "image_files.sort()\n",
        "label_files.sort()\n",
        "\n",
        "# Create the dataset and DataLoader\n",
        "train_dataset = SegmentationDataset(image_files, label_files, transform=preprocess_image)\n",
        "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDz9a6Isl80S",
        "outputId": "99aea2d4-1d96-48a7-d3cd-6af1cfa5e59d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading DeepLabV3"
      ],
      "metadata": {
        "id": "uSTPMD7hm-cD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "# Loading the pretrained DeepLabV3+ model\n",
        "deeplab = models.deeplabv3_resnet101(pretrained=True)\n",
        "\n",
        "# Modifying the first convolutional layer to accept 12 channels instead of 3\n",
        "deeplab.backbone.conv1 = nn.Conv2d(12, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "deeplab.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "MF2OLABem6ae",
        "outputId": "da2c81b0-d342-471a-f117-6ff2e6a27489"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming image_files and label_files contain validation data as well\n",
        "val_dataset = SegmentationDataset(image_files, label_files, transform=preprocess_image)\n",
        "\n",
        "# Create a DataLoader for validation (batch size can be the same as for training or different)\n",
        "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "Uo8cshPLuhDj"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Accuracy"
      ],
      "metadata": {
        "id": "uun3nGaOsVJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_pixel_accuracy(predictions, labels):\n",
        "    \"\"\"\n",
        "    Compute pixel accuracy (the ratio of correctly predicted pixels).\n",
        "\n",
        "    Args:\n",
        "        predictions: Predicted segmentation masks (batch_size, H, W)\n",
        "        labels: Ground truth segmentation masks (batch_size, H, W)\n",
        "\n",
        "    Returns:\n",
        "        accuracy: Pixel accuracy\n",
        "    \"\"\"\n",
        "    correct = (predictions == labels).sum().float()\n",
        "    total = labels.numel()\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy.item()\n"
      ],
      "metadata": {
        "id": "vntPNyohsW-d"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "\n",
        "total_accuracy = 0\n",
        "num_batches = 0\n",
        "\n",
        "# Loop through the DataLoader for evaluation\n",
        "for images, labels in val_loader:  # Replace val_loader with your validation/test DataLoader\n",
        "    with torch.no_grad():\n",
        "        images = images.float()  # Ensure images are in float32 format\n",
        "\n",
        "        # Perform the forward pass to get the predictions\n",
        "        outputs = deeplab(images)['out']\n",
        "        predictions = torch.argmax(outputs, dim=1)  # Predicted segmentation map\n",
        "\n",
        "        # Compute metrics for each batch\n",
        "        accuracy = compute_pixel_accuracy(predictions, labels)\n",
        "\n",
        "        # Aggregate results\n",
        "        total_accuracy += accuracy\n",
        "        num_batches += 1\n",
        "\n",
        "# Average results across batches\n",
        "mean_accuracy = total_accuracy / num_batches\n",
        "\n",
        "# Display the results\n",
        "print(f'Mean Pixel Accuracy: {mean_accuracy}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TEkLtceusfHb",
        "outputId": "efd0483d-d348-4d7b-8f2e-872a377bdc0d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Pixel Accuracy: 0.9519857431386972\n"
          ]
        }
      ]
    }
  ]
}